# @package _global_

defaults:
  - base
  - /preset/datasets/db_improved
  - /preset/models/encoder/timm_backbone
  - /preset/models/decoder/unet
  - /preset/models/head/db_head
  - /preset/models/loss/db_loss
  - /preset/lightning_modules/base
  - _self_

exp_name: "onecycle_lr_002"

models:
  optimizer:
    _target_: torch.optim.AdamW
    lr: 0.002  # 더 높은 학습률
    weight_decay: 1e-4
    betas: [0.9, 0.999]

  # 높은 학습률 + CosineAnnealing 스케줄러
  scheduler:
    _target_: torch.optim.lr_scheduler.CosineAnnealingLR
    T_max: 20  # 에포크 수와 맞춤
    eta_min: 1e-6

trainer:
  max_epochs: 20